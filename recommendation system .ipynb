{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86BD1PhAaU0J",
        "outputId": "156e1964-d6e3-407e-bf4e-cb4910b581e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "j23blab6aVoO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('anime.csv')"
      ],
      "metadata": {
        "id": "Zim76ZIAaoat"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show basic info\n",
        "print(\"Initial shape:\", df.shape)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2SlWp3oa8dI",
        "outputId": "4994f254-d3b2-4151-fec6-eb03373b9485"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape: (12294, 7)\n",
            "Index(['anime_id', 'name', 'genre', 'type', 'episodes', 'rating', 'members'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values\n",
        "df['genre'] = df['genre'].fillna('')\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mean())"
      ],
      "metadata": {
        "id": "jpnOl5mRbHJK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: drop duplicates if any\n",
        "df = df.drop_duplicates(subset='name')"
      ],
      "metadata": {
        "id": "ZwTCzS79bKEI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF on genre column\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['genre'])"
      ],
      "metadata": {
        "id": "3L0KCKK_bMZe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "2Ww1EnyEbOcL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build index mapping of anime names to DataFrame index\n",
        "anime_indices = pd.Series(df.index, index=df['name']).drop_duplicates()"
      ],
      "metadata": {
        "id": "QwGKKKVbbQz9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation function\n",
        "def recommend_anime(title, top_n=10):\n",
        "    if title not in anime_indices:\n",
        "        return f\"'{title}' not found in dataset.\"\n",
        "    idx = anime_indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]  # exclude the anime itself\n",
        "\n",
        "    anime_indices_similar = [i[0] for i in sim_scores]\n",
        "    return df[['name', 'genre', 'rating']].iloc[anime_indices_similar]"
      ],
      "metadata": {
        "id": "8knAPgB4bS4e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate ground truth by splitting known similar genres\n",
        "df['genre_label'] = df['genre'].apply(lambda x: x.split(',')[0] if x else 'Unknown')\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b0nIWwdvbUu2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple evaluation: check if test anime genre appears in top-N similar ones from train\n",
        "def evaluate_model(top_n=10):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for _, row in test.iterrows():\n",
        "        title = row['name']\n",
        "        true_genre = row['genre_label']\n",
        "\n",
        "        if title not in anime_indices:\n",
        "            continue\n",
        "\n",
        "        recommendations = recommend_anime(title, top_n=top_n)\n",
        "        if isinstance(recommendations, str):  # error message\n",
        "            continue\n",
        "\n",
        "        predicted_genres = recommendations['genre'].apply(lambda g: g.split(',')[0] if g else 'Unknown').tolist()\n",
        "\n",
        "        y_true.append(true_genre)\n",
        "        y_pred.append(predicted_genres[0] if predicted_genres else 'Unknown')\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEvaluation:\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "_X9_z6vkbguA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run an example\n",
        "print(\"\\nRecommended Anime for 'Naruto':\")\n",
        "print(recommend_anime('Naruto'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjN8iVFHbo4h",
        "outputId": "77e730bc-6d61-4643-b978-740fcf071192"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Anime for 'Naruto':\n",
            "                                                   name  \\\n",
            "615                                  Naruto: Shippuuden   \n",
            "841                                              Naruto   \n",
            "1103  Boruto: Naruto the Movie - Naruto ga Hokage ni...   \n",
            "1343                                        Naruto x UT   \n",
            "1472        Naruto: Shippuuden Movie 4 - The Lost Tower   \n",
            "1573  Naruto: Shippuuden Movie 3 - Hi no Ishi wo Tsu...   \n",
            "2458               Naruto Shippuuden: Sunny Side Battle   \n",
            "2997  Naruto Soyokazeden Movie: Naruto to Mashin to ...   \n",
            "7628                            Kyutai Panic Adventure!   \n",
            "784          Naruto: Shippuuden Movie 6 - Road to Ninja   \n",
            "\n",
            "                                                  genre  rating  \n",
            "615   Action, Comedy, Martial Arts, Shounen, Super P...    7.94  \n",
            "841   Action, Comedy, Martial Arts, Shounen, Super P...    7.81  \n",
            "1103  Action, Comedy, Martial Arts, Shounen, Super P...    7.68  \n",
            "1343  Action, Comedy, Martial Arts, Shounen, Super P...    7.58  \n",
            "1472  Action, Comedy, Martial Arts, Shounen, Super P...    7.53  \n",
            "1573  Action, Comedy, Martial Arts, Shounen, Super P...    7.50  \n",
            "2458  Action, Comedy, Martial Arts, Shounen, Super P...    7.26  \n",
            "2997  Action, Comedy, Martial Arts, Shounen, Super P...    7.11  \n",
            "7628         Action, Martial Arts, Shounen, Super Power    5.21  \n",
            "784   Action, Adventure, Martial Arts, Shounen, Supe...    7.84  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVId4TtIcBU1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "498c896f"
      },
      "source": [
        "# Task\n",
        "Explain the error in the selected code. If possible, fix the error and incorporate the changes into the existing code. Otherwise, try to diagnose the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68957470"
      },
      "source": [
        "## Recalculate cosine similarity\n",
        "\n",
        "### Subtask:\n",
        "Calculate the cosine similarity matrix using the `train` dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "871fbdeb"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply the fitted TF-IDF vectorizer to the training data and calculate the cosine similarity matrix for the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31431129"
      },
      "source": [
        "tfidf_matrix_train = tfidf.transform(train['genre'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix_train, tfidf_matrix_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f098bea"
      },
      "source": [
        "## Update anime indices\n",
        "\n",
        "### Subtask:\n",
        "Rebuild the `anime_indices` mapping using the indices of the `train` dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5604896"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `anime_indices` mapping using the index and name from the training set and remove duplicates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0628c3a2"
      },
      "source": [
        "anime_indices = pd.Series(train.index, index=train['name']).drop_duplicates()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a58f1054"
      },
      "source": [
        "## Run evaluation\n",
        "\n",
        "### Subtask:\n",
        "Execute the `evaluate_model` function using the updated `anime_indices` and `cosine_sim` matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdc5807"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the evaluate_model function with top_n=5 to evaluate the recommendation model using the updated anime_indices and cosine_sim matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFpFJUlHczQb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ab47bd8"
      },
      "source": [
        "## Recalculate cosine similarity\n",
        "\n",
        "### Subtask:\n",
        "Calculate the cosine similarity matrix using the `train` dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221f8f5c"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply the fitted TF-IDF vectorizer to the training data and calculate the cosine similarity matrix for the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6bf2b3d"
      },
      "source": [
        "# Assuming 'tfidf' vectorizer is already fitted on the combined genre data\n",
        "tfidf_matrix_train = tfidf.transform(train['genre'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix_train, tfidf_matrix_train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7edef912"
      },
      "source": [
        "## Update Anime Indices\n",
        "\n",
        "### Subtask:\n",
        "Rebuild the `anime_indices` mapping using the indices of the `train` dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5acf6ba"
      },
      "source": [
        "**Reasoning**:\n",
        "Recreate the `anime_indices` Series using the 'name' column and the index of the `train` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1125b8e5"
      },
      "source": [
        "# Build index mapping of anime names to DataFrame index using the train data\n",
        "anime_indices = pd.Series(train.index, index=train['name']).drop_duplicates()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Improved Data Preprocessing ---\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle missing genres with placeholder\n",
        "df['genre'] = df['genre'].fillna(\"Unknown\")\n",
        "\n",
        "# Handle 'Unknown' or '-' or invalid ratings\n",
        "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mean())\n",
        "\n",
        "# Clean and convert episode values\n",
        "df['episodes'] = pd.to_numeric(df['episodes'], errors='coerce')\n",
        "df['episodes'] = df['episodes'].fillna(df['episodes'].median())\n",
        "\n",
        "# Optional: Lowercase genre for consistency\n",
        "df['genre'] = df['genre'].str.lower().str.strip()\n"
      ],
      "metadata": {
        "id": "1yTVQANjp06i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interview Question Answers"
      ],
      "metadata": {
        "id": "b2RgMkntqEfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Can you explain the difference between user-based and item-based collaborative filtering?\n",
        "# User-Based Collaborative Filtering:\n",
        "\n",
        "# Recommends items to a user based on the preferences of other similar users.\n",
        "\n",
        "# It assumes that if two users liked similar items in the past, they will likely agree on other items too.\n",
        "\n",
        "# Example: If User A and User B both liked \"Naruto\" and \"Bleach\", and User A also liked \"One Piece\", then User B might also like \"One Piece\".\n",
        "\n",
        "# Item-Based Collaborative Filtering:\n",
        "\n",
        "# Recommends items based on the similarity between items, not users.\n",
        "\n",
        "# It checks which items are often liked together and recommends similar items to the user based on their past likes.\n",
        "\n",
        "# Example: If users who liked \"Naruto\" also liked \"Bleach\", then \"Bleach\" will be recommended to someone who likes \"Naruto\".\n",
        "\n",
        "# Key Differences:\n",
        "\n",
        "# User-based focuses on user similarity, item-based focuses on item similarity.\n",
        "\n",
        "# Item-based is often more stable when the number of users is high and constantly changing.\n",
        "\n",
        "# 2. What is collaborative filtering, and how does it work?\n",
        "# Collaborative Filtering is a recommendation technique that makes automatic predictions about a user’s interests by collecting preferences from many users (collaboration).\n",
        "\n",
        "# How It Works:\n",
        "\n",
        "# It uses a user-item interaction matrix (like ratings or views).\n",
        "\n",
        "# Finds patterns in the matrix to identify similarities.\n",
        "\n",
        "# Two main types:\n",
        "\n",
        "# User-Based: \"Users like you also liked...\"\n",
        "\n",
        "# Item-Based: \"Items similar to what you liked...\"\n",
        "\n",
        "# Advantages:\n",
        "\n",
        "# No need for deep item content analysis (works with sparse data).\n",
        "\n",
        "# Can discover surprising patterns or associations.\n",
        "\n",
        "# Challenges:\n",
        "\n",
        "# Cold Start Problem: New users/items have insufficient data.\n",
        "\n",
        "# Data Sparsity: Not all users rate all items.\n",
        "\n",
        "# Scalability: Large datasets need efficient computation."
      ],
      "metadata": {
        "id": "ZYX43Yr-qA2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}